# music-bardo

This repository contains the source code to reproduce the results of the paper "Computer-Generated Music for Tabletop Role-Playing Games".

## Dependencies

- tensorflow-2.1
- pretty_midi

## Download "ADL Piano Midi" Dataset

## Encode "ADL Piano Midi" Dataset as Text

Encode all training MIDI files as text:

``
python3 midi_encoder.py --midi ../adl-piano-midi/midi/train --transp 12 --tempo 3 --vel 3 --vocab trained/transformer/vocab.json
``

Encode all testing MIDI pieces as text:

``
python3 midi_encoder.py --midi ../adl-piano-midi/midi/test --transp 12 --tempo 3 --vel 3
``

After running this script, every ".mid" file in the train and test directories should have an associated ".txt" version
(unless there was an error when parsing a giving file). These ".txt" files include 12 * 3 * 3 = 108 different versions
of the original piece, which are generated by:

1. Transposing the original piece to all keys (--transp 12).
2. Increased and decresead the tempo of the original piece by 10% (--tempo 3).
3. Increased and decresead the velocity of the original piece by 10% (--tempo 3).

## Train Generative (Unsupervised) Large Transformer

To train the generative transformer that will be used for generation:

``
python3 train_transformer.py --conf train_conf.json
``

With the default configuration, the training takes approximately 10 days using two NVIDIA GPUs.
